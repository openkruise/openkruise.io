"use strict";(self.webpackChunkopenkruise_io=self.webpackChunkopenkruise_io||[]).push([[6937],{3905:function(e,n,t){t.d(n,{Zo:function(){return c},kt:function(){return m}});var a=t(67294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function r(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var l=a.createContext({}),d=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},c=function(e){var n=d(e.components);return a.createElement(l.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,c=r(e,["components","mdxType","originalType","parentName"]),u=d(t),m=i,h=u["".concat(l,".").concat(m)]||u[m]||p[m]||o;return t?a.createElement(h,s(s({ref:n},c),{},{components:t})):a.createElement(h,s({ref:n},c))}));function m(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=t.length,s=new Array(o);s[0]=u;var r={};for(var l in n)hasOwnProperty.call(n,l)&&(r[l]=n[l]);r.originalType=e,r.mdxType="string"==typeof e?e:i,s[1]=r;for(var d=2;d<o;d++)s[d]=t[d];return a.createElement.apply(null,s)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},4648:function(e,n,t){t.r(n),t.d(n,{assets:function(){return c},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return r},metadata:function(){return d},toc:function(){return p}});var a=t(87462),i=t(63366),o=(t(67294),t(3905)),s=["components"],r={slug:"elastic",title:"A Flexible and Configurable Serverless Elastic Solution at the Workload Level",authors:["AiRanthem"],tags:["workload","uniteddeployment","workloadspread","best-practice"]},l="A Flexible and Configurable Serverless Elastic Solution at the Workload Level",d={permalink:"/blog/elastic",editUrl:"https://github.com/openkruise/openkruise.io/edit/master/blog/2025-02-19-elastic-components.md",source:"@site/blog/2025-02-19-elastic-components.md",title:"A Flexible and Configurable Serverless Elastic Solution at the Workload Level",description:"Serverless represents an extension of cloud computing, inheriting its most significant feature: on-demand elastic",date:"2025-02-19T00:00:00.000Z",formattedDate:"February 19, 2025",tags:[{label:"workload",permalink:"/blog/tags/workload"},{label:"uniteddeployment",permalink:"/blog/tags/uniteddeployment"},{label:"workloadspread",permalink:"/blog/tags/workloadspread"},{label:"best-practice",permalink:"/blog/tags/best-practice"}],readingTime:12.69,truncated:!1,authors:[{name:"Tianyun Zhong",title:"Member of OpenKruise",url:"https://github.com/AiRanthem",imageURL:"https://github.com/AiRanthem.png",key:"AiRanthem"}],frontMatter:{slug:"elastic",title:"A Flexible and Configurable Serverless Elastic Solution at the Workload Level",authors:["AiRanthem"],tags:["workload","uniteddeployment","workloadspread","best-practice"]},nextItem:{title:"OpenKruise V1.4 Release, New Job Sidecar Terminator Capability",permalink:"/blog/openkruise-1.4"}},c={authorsImageUrls:[void 0]},p=[{value:"Example Configuration",id:"example-configuration",level:2},{value:"Powerful Partitioning Capability",id:"powerful-partitioning-capability",level:2},{value:"Flexible Scheduling Configuration",id:"flexible-scheduling-configuration",level:3},{value:"Detailed Pod Customization",id:"detailed-pod-customization",level:3},{value:"WorkloadSpread&#39;s Pod Mutating Webhook Mechanism",id:"workloadspreads-pod-mutating-webhook-mechanism",level:2},{value:"Limitations of WorkloadSpread",id:"limitations-of-workloadspread",level:2},{value:"Potential Risks of Webhook",id:"potential-risks-of-webhook",level:3},{value:"Limitations of Acting on Pods",id:"limitations-of-acting-on-pods",level:3},{value:"Case Study 1: Bandwidth Package Allocation in Large-Scale Load Testing",id:"case-study-1-bandwidth-package-allocation-in-large-scale-load-testing",level:2},{value:"Case Study 2: Compatibility for Scaling Managed K8S Cluster Services to Serverless Instances",id:"case-study-2-compatibility-for-scaling-managed-k8s-cluster-services-to-serverless-instances",level:2},{value:"Example Configuration",id:"example-configuration-1",level:2},{value:"Advantages of UnitedDeployment",id:"advantages-of-uniteddeployment",level:2},{value:"All-In-One Elastic Application Management",id:"all-in-one-elastic-application-management",level:3},{value:"Advanced Subset Management",id:"advanced-subset-management",level:3},{value:"Adaptive Elasticity",id:"adaptive-elasticity",level:3},{value:"Limitations of UnitedDeployment",id:"limitations-of-uniteddeployment",level:2},{value:"Case Study 1: Elastic Scaling of Pods to Virtual Nodes with Adaptation for Serverless Containers",id:"case-study-1-elastic-scaling-of-pods-to-virtual-nodes-with-adaptation-for-serverless-containers",level:2},{value:"Case Study 2: Allocating Different Resources to Pods with Different CPU Types",id:"case-study-2-allocating-different-resources-to-pods-with-different-cpu-types",level:2}],u={toc:p};function m(e){var n=e.components,t=(0,i.Z)(e,s);return(0,o.kt)("wrapper",(0,a.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Serverless represents an extension of cloud computing, inheriting its most significant feature: on-demand elastic\nscaling. This model design allows developers to focus on application logic without concerning themselves with deployment\nresources, thereby fully leveraging resource scalability to provide superior elasticity capabilities. Enterprises can\nalso genuinely benefit from true pay-as-you-go characteristics. Consequently, more cloud providers are converging\ntowards this new architectural paradigm."),(0,o.kt)("p",null,'The core capability of "flexible configurability" in Serverless technology focuses on enabling specific cloud usage\nscenarios to fully utilize cloud resources through simple, minimally invasive, and highly configurable methods. Its\nessence lies in resolving the conflict between capacity planning and actual cluster load configuration. This article\nwill sequentially introduce two configurable components \u2014 ',(0,o.kt)("inlineCode",{parentName:"p"},"WorkloadSpread")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"UnitedDeployment")," \u2014 discussing their\ncore capabilities, technical principles, advantages and disadvantages, as well as real-world applications. Through these\ndiscussions, we aim to share OpenKruise's technical evolution and considerations in addressing Serverless workload\nelasticity."),(0,o.kt)("h1",{id:"overview-of-elastic-scenarios"},"Overview of Elastic Scenarios"),(0,o.kt)("p",null,"As Serverless technology matures, more enterprises prefer using cloud resources (such as Alibaba Cloud ACS Serverless\ncontainer instances) over on-premise resources (like managed resource pools or on-premise IDC data centers) to host\napplications with temporary, tidal, or bursty characteristics. This approach enhances resource utilization efficiency\nand reduces overall costs by adopting a pay-as-you-go model. Below are some typical elastic scenarios:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Prioritize using on-premise resources in offline IDC data centers; scale application to the cloud when\nresources are insufficient."),(0,o.kt)("li",{parentName:"ol"},"Prefer using pre-paid resource pool in the cloud; use pay-as-you-go Serverless instances for additional replicas\nwhen resources are insufficient."),(0,o.kt)("li",{parentName:"ol"},"Use high-quality stable compute power (e.g., dedicated cloud server instances) first; then use lower-quality compute\npower (e.g., Spot instances)."),(0,o.kt)("li",{parentName:"ol"},"Configure different resource quantities for container replicas deployed on different compute platforms (e.g., X86,\nARM, Serverless instances) to achieve similar performance."),(0,o.kt)("li",{parentName:"ol"},"Inject different middleware configurations into replicas deployed on nodes versus Serverless environments (e.g.,\nshared Daemon on nodes, Sidecar injection on Serverless).")),(0,o.kt)("p",null,"These components introduced in this article offer distinct advantages in solving the above problems. Users can choose\nappropriate capabilities based on their specific scenarios to effectively leverage elastic compute power."),(0,o.kt)("h1",{id:"capabilities-and-advantageous-scenarios-of-two-components"},"Capabilities and Advantageous Scenarios of Two Components"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"WorkloadSpread"),": Utilizes a Mutating Webhook to intercept Pod creation requests that meet certain criteria and\napply Patch operations to inject differentiated configurations. Suitable for existing applications requiring multiple\nelastic partitions with customized Pod Metadata and Spec fields."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"UnitedDeployment"),": A workload with built-in capability of elastic partitioning and pod customization, offering\nstronger\nelasticity and capacity planning capabilities. Ideal for new applications needing detailed partitioning and individual\nconfigurations for each partition.")),(0,o.kt)("h1",{id:"workloadspread-an-elastic-strategy-plugin-based-on-pod-mutating-webhook"},"WorkloadSpread: An Elastic Strategy Plugin Based on Pod Mutating Webhook"),(0,o.kt)("p",null,"WorkloadSpread is a bypass component provided by the OpenKruise community that spreads target workload Pods across\ndifferent types of subsets according to specific rules, enhancing multi-region and elastic deployment capabilities\nwithout modifying the original workload. It supports almost all native or custom Kubernetes workloads, ensuring\nadaptability and flexibility in various environments."),(0,o.kt)("h2",{id:"example-configuration"},"Example Configuration"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps.kruise.io/v1alpha1\nkind: WorkloadSpread\nmetadata:\n  name: workloadspread-demo\nspec:\n  targetRef: # Supports almost all native or custom Kubernetes workloads\n    apiVersion: apps/v1 | apps.kruise.io/v1alpha1\n    kind: Deployment | CloneSet\n    name: workload-xxx\n  subsets:\n    - name: subset-a\n      # The first three replicas will be scheduled to this Subset\n      maxReplicas: 3\n      # Pod affinity configuration\n      requiredNodeSelectorTerm:\n        matchExpressions:\n          - key: topology.kubernetes.io/zone\n            operator: In\n            values:\n              - zone-a\n      patch:\n        # Inject a custom label to Pods scheduled to this Subset\n        metadata:\n          labels:\n            xxx-specific-label: xxx\n    - name: subset-b\n      # Deploy to Serverless clusters, no capacity and unlimited replicas\n      requiredNodeSelectorTerm:\n        matchExpressions:\n          - key: topology.kubernetes.io/zone\n            operator: In\n            values:\n              - acs-cn-hangzhou\n  scheduleStrategy:\n    # Adaptive mode will reschedule failed Pods to other Subsets\n    type: Adaptive | Fixed\n    adaptive:\n      rescheduleCriticalSeconds: 30\n")),(0,o.kt)("h2",{id:"powerful-partitioning-capability"},"Powerful Partitioning Capability"),(0,o.kt)("p",null,"WorkloadSpread spreads Pods into different elastic partitions using Subsets, ",(0,o.kt)("strong",{parentName:"p"},"scaling up forward and scaling down\nbackward based on Subset order.")),(0,o.kt)("h3",{id:"flexible-scheduling-configuration"},"Flexible Scheduling Configuration"),(0,o.kt)("p",null,"At the Subset level, WorkloadSpread supports selecting nodes via Labels and configuring advanced options such as taints\nand tolerations. For example, ",(0,o.kt)("inlineCode",{parentName:"p"},"requiredNodeSelectorTerm")," specifies mandatory node attributes,\n",(0,o.kt)("inlineCode",{parentName:"p"},"preferredNodeSelectorTerms"),"sets preferred node attributes, and ",(0,o.kt)("inlineCode",{parentName:"p"},"tolerations")," configures Pod tolerance for node taints.\nThese configurations allow precise control over Pod scheduling and distribution."),(0,o.kt)("p",null,"At the global level, WorkloadSpread supports two scheduling strategies via the ",(0,o.kt)("inlineCode",{parentName:"p"},"scheduleStrategy")," field: Fixed and\nAdaptive. The Fixed strategy ensures strict adherence to predefined Subset distributions, while the Adaptive strategy\nprovides higher flexibility by automatically rescheduling Pods to other available Subsets when necessary."),(0,o.kt)("h3",{id:"detailed-pod-customization"},"Detailed Pod Customization"),(0,o.kt)("p",null,"In Subset configurations, the ",(0,o.kt)("inlineCode",{parentName:"p"},"patch")," field allows for fine-grained customization of Pods scheduled to that subset.\nSupported fields include container images, resource limits, environment variables, volume mounts, startup commands,\nprobe configurations, and labels. This decouples Pod specifications from environment adaptations, enabling flexible\nworkload adjustments for various partition environments."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'...\n# patch pod with a topology label:\npatch:\n  metadata:\n    labels:\n      topology.application.deploy/zone: "zone-a"\n...\n')),(0,o.kt)("p",null,"The example above demonstrates how to add or modify a label to all Pods in a Subset."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'...\n# patch pod container resources:\npatch:\n  spec:\n    containers:\n      - name: main\n        resources:\n          limit:\n            cpu: "2"\n            memory: 800Mi\n...\n')),(0,o.kt)("p",null,"The example above demonstrates how to add or modify the Pod Spec."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"...\n# patch pod container env with a zone name:\npatch:\n  spec:\n    containers:\n      - name: main\n        env:\n          - name: K8S_AZ_NAME\n            value: zone-a\n...\n")),(0,o.kt)("p",null,"The example above demonstrates how to add or modify a container environment variable."),(0,o.kt)("h2",{id:"workloadspreads-pod-mutating-webhook-mechanism"},"WorkloadSpread's Pod Mutating Webhook Mechanism"),(0,o.kt)("p",null,"WorkloadSpread operates directly on Pods created by the target workload via Pod Mutating Webhook, ensuring non-intrusive\noperation. When a Pod creation request meets the criteria, the Webhook intercepts it, reads the corresponding\nWorkloadSpread configuration, selects an appropriate Subset, and modifies the Pod configuration accordingly. The\ncontroller maintains the controller.kubernetes.io/pod-deletion-cost label to ensure correct downsizing order."),(0,o.kt)("h2",{id:"limitations-of-workloadspread"},"Limitations of WorkloadSpread"),(0,o.kt)("h3",{id:"potential-risks-of-webhook"},"Potential Risks of Webhook"),(0,o.kt)("p",null,"WorkloadSpread depends on Pod Mutating Webhook to function, which intercepts all Pod creation requests in the cluster.\nIf the Webhook Pod (kruise-manager) experiences performance issues or failures, it may prevent new Pods from being\ncreated. Additionally, during large-scale scaling operations, Webhook can become a performance bottleneck."),(0,o.kt)("h3",{id:"limitations-of-acting-on-pods"},"Limitations of Acting on Pods"),(0,o.kt)("p",null,"While acting on Pods reduces business intrusion, it introduces limitations. For instance, CloneSet's gray release ratio\ncannot be controlled per Subset."),(0,o.kt)("h2",{id:"case-study-1-bandwidth-package-allocation-in-large-scale-load-testing"},"Case Study 1: Bandwidth Package Allocation in Large-Scale Load Testing"),(0,o.kt)("p",null,"A company needed to perform load testing before a major shopping festival. They developed a load-agent program to\ngenerate requests and used a CloneSet to manage agent replicas. To save costs, they purchased 10 shared bandwidth\npackages (each supporting 300 Pods) and aimed to dynamically allocate them to elastic agent replicas."),(0,o.kt)("p",null,"They configured a WorkloadSpread with 11 Subsets: the first 10 Subsets had a capacity of 300 and patched Pod Annotations\nto bind specific bandwidth packages; the last Subset had no capacity and no bandwidth package, preventing extra\nbandwidth allocation if more than 3000 replicas were created."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps.kruise.io/v1alpha1\nkind: WorkloadSpread\nmetadata:\n  name: bandwidth-spread\n  namespace: loadtest\nspec:\n  targetRef:\n    apiVersion: apps.kruise.io/v1alpha1\n    kind: CloneSet\n    name: load-agent-XXXXX\n  subsets:\n    - name: bandwidthPackage-1\n      maxReplicas: 300\n      patch:\n        metadata:\n          annotations:\n            k8s.aliyun.com/eip-common-bandwidth-package-id: <id1>\n\n    - ...\n\n    - name: bandwidthPackage-10\n      maxReplicas: 300\n      patch:\n        metadata:\n          annotations:\n            k8s.aliyun.com/eip-common-bandwidth-package-id: <id10>\n    - name: no-eip\n")),(0,o.kt)("h2",{id:"case-study-2-compatibility-for-scaling-managed-k8s-cluster-services-to-serverless-instances"},"Case Study 2: Compatibility for Scaling Managed K8S Cluster Services to Serverless Instances"),(0,o.kt)("p",null,"A company had a web service running on an IDC that needed to scale up due to business growth but could not\nexpand the local data center. They chose to use virtual nodes to access cloud-based Serverless elastic compute power,\nforming a hybrid cloud. Their application used acceleration services\nlike ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/fluid-cloudnative/fluid"},"Fluid"),", which were pre-deployed on nodes in\nthe IDC but not available in the serverless subset. Therefore, they needed to inject a sidecar into cloud Pods to\nprovide acceleration capabilities."),(0,o.kt)("p",null,"To achieve this without modifying the existing Deployment's 8 replicas, they used WorkloadSpread to add a label to Pods\nscaled to each subset, which controlled the Fluid sidecar injection."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps.kruise.io/v1alpha1\nkind: WorkloadSpread\nmetadata:\n  name: data-processor-spread\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: data-processor\n  subsets:\n    - name: local\n      maxReplicas: 8\n      patch:\n        metadata:\n          labels:\n            serverless.fluid.io/inject: "false"\n    - name: aliyun-acs\n      patch:\n        metadata:\n          labels:\n            serverless.fluid.io/inject: "true"\n')),(0,o.kt)("h1",{id:"uniteddeployment-a-native-workload-with-built-in-elasticity"},"UnitedDeployment: A Native Workload with Built-in Elasticity"),(0,o.kt)("p",null,"UnitedDeployment is an advanced workload provided by the OpenKruise community that natively supports\npartition management. Unlike WorkloadSpread, which enhances basic workloads, UnitedDeployment offers\na new mode for managing partitioned elastic applications. It defines applications through a single template, and\nthe controller creates and manages multiple secondary workloads to match different subsets. UnitedDeployment manages the\nentire lifecycle of applications within a single resource, including definition, partitioning, scaling, and upgrades."),(0,o.kt)("h2",{id:"example-configuration-1"},"Example Configuration"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps.kruise.io/v1alpha1\nkind: UnitedDeployment\nmetadata:\n  name: sample-ud\nspec:\n  replicas: 6\n  selector:\n    matchLabels:\n      app: sample\n  template:\n    cloneSetTemplate:\n      metadata:\n        labels:\n          app: sample\n      spec:\n        # CloneSet Spec\n        ...\n  topology:\n    subsets:\n      - name: ecs\n        nodeSelectorTerm:\n          matchExpressions:\n            - key: node-type\n              operator: In\n              values:\n                - ecs\n        maxReplicas: 2\n      - name: acs-serverless\n        nodeSelectorTerm:\n          matchExpressions:\n            - key: node-type\n              operator: In\n              values:\n                - acs-virtual-kubelet\n")),(0,o.kt)("h2",{id:"advantages-of-uniteddeployment"},"Advantages of UnitedDeployment"),(0,o.kt)("h3",{id:"all-in-one-elastic-application-management"},"All-In-One Elastic Application Management"),(0,o.kt)("p",null,"UnitedDeployment offers comprehensive all-in-one application management, enabling users to define applications, manage\nsubsets, scale, and upgrade using a single resource."),(0,o.kt)("p",null,"The UnitedDeployment controller manages a corresponding type of secondary workload for each subset based on the\nworkload template, without requiring additional attention from the user. Users only need to manage the application\ntemplate and subsets; the UnitedDeployment controller will handle subsequent management tasks for each secondary\nworkload, including creation, modification, and deletion. The controller also monitors the status of Pods created by\nthese workloads when necessary to make corresponding adjustments."),(0,o.kt)("p",null,"It is the secondary workload controllers implement the specific scaling and updating operations. Thus, scaling and\nupdating using UnitedDeployment produces exactly the same effect as directly using the corresponding workload. For\nexample, a UnitedDeployment will inherit the same grayscale publishing and in-place upgrade capabilities from CloneSet\nwhen created with a CloneSet template."),(0,o.kt)("h3",{id:"advanced-subset-management"},"Advanced Subset Management"),(0,o.kt)("p",null,"UnitedDeployment incorporates two capacity allocation algorithms, enabling users to handle various scenarios of elastic\napplications through detailed subset capacity configurations."),(0,o.kt)("p",null,"The elastic allocation algorithm implements a classic elastic capacity allocation method similar to WorkloadSpread: by\nsetting upper and lower capacity limits for each subset, Pods are scaled up in the defined order of subsets and scaled\ndown in reverse order. This method has been thoroughly introduced earlier, so it will not be elaborated further here."),(0,o.kt)("p",null,"The specified allocation algorithm represents a new approach to capacity allocation. It directly assigns fixed numbers\nor percentages to some subsets and reserves at least one elastic subset to distribute the remaining replicas."),(0,o.kt)("p",null,"In addition to capacity allocation, UnitedDeployment also allows customizing any Pod Spec fields (including container\nimages) for each subset, which is similar to WorkloadSpread. This grants UnitedDeployment's subset configuration with\npowerful flexibility."),(0,o.kt)("h3",{id:"adaptive-elasticity"},"Adaptive Elasticity"),(0,o.kt)("p",null,"UnitedDeployment offers robust adaptive elasticity, automating scaling and rescheduling operations to reduce operational\noverhead. It supports Kubernetes Horizontal Pod Autoscaler (HPA), enabling automatic scaling based on predefined\nconditions while adhering strictly to subset configurations."),(0,o.kt)("p",null,"UnitedDeployment also offers adaptive Pod rescheduling capabilities similar to WorkloadSpread. Additionally, it allows\nconfiguration of timeout durations for scheduling failures and recovery times for subsets from unscheduable status,\nproviding enhanced control over adaptive scheduling."),(0,o.kt)("h2",{id:"limitations-of-uniteddeployment"},"Limitations of UnitedDeployment"),(0,o.kt)("p",null,"The many advantages of UnitedDeployment stem from its all-in-one management capabilities as an independent workload.\nHowever, this also leads to the drawback of higher business transformation intrusiveness. For users' existing\napplication, it is necessary to modify PaaS systems and tools (such as operation and maintenance systems, release\nsystems, etc.) to switch from existing workloads like Deployment and CloneSet to UnitedDeployment."),(0,o.kt)("h2",{id:"case-study-1-elastic-scaling-of-pods-to-virtual-nodes-with-adaptation-for-serverless-containers"},"Case Study 1: Elastic Scaling of Pods to Virtual Nodes with Adaptation for Serverless Containers"),(0,o.kt)("p",null,"Cloud providers typically offer three types of Kubernetes services:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Managed clusters with fixed nodes using cloud servers purchased by users."),(0,o.kt)("li",{parentName:"ol"},"Serverless clusters delivering container computing power directly via virtual node technology."),(0,o.kt)("li",{parentName:"ol"},"Hybrid clusters containing both managed nodes and virtual nodes.")),(0,o.kt)("p",null,"In this case, a company planned to launch a new service with significant peak-to-valley traffic differences (up to\ntenfold). To handle this characteristic, they purchased a batch of cloud servers to form a managed cluster nodepool for\nhandling baseline traffic and intended to quickly scale out new replicas to a serverless subset during peak hours.\nAdditionally, their application required extra configuration to run in the Serverless environment. Below is an example\nconfiguration:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps.kruise.io/v1alpha1\nkind: UnitedDeployment\nmetadata:\n  name: elastic-app\nspec:\n  # Omitted business workload template\n  ...\n  topology:\n    # Enable Adaptive scheduling to dispatch Pod replicas to ECS node pools and ACS instances adaptively\n    scheduleStrategy:\n      type: Adaptive\n      adaptive:\n        # Start scheduling to ACS Serverless instances 10 seconds after ECS node scheduling failure\n        rescheduleCriticalSeconds: 10\n        # Do not schedule to ECS nodes within one hour after the above scheduling failure\n        unschedulableLastSeconds: 3600\n    subsets:\n      # Prioritize ECS without an upper limit; only schedule to ACS when ECS fails\n      # During scale-in, delete ACS instances first, then ECS node pool Pods\n      - name: ecs\n        nodeSelectorTerm:\n          matchExpressions:\n            - key: type\n              operator: NotIn\n              values:\n                - acs-virtual-kubelet\n      - name: acs-serverless\n        nodeSelectorTerm:\n          matchExpressions:\n            - key: type\n              operator: In\n              values:\n                - acs-virtual-kubelet\n          # Use patch to modify environment variables for Pods scheduled to elastic computing power, enabling Serverless mode\n        patch:\n          spec:\n            containers:\n              - name: main\n                env:\n                  - name: APP_RUNTIME_MODE\n                    value: SERVERLESS\n---\n# Combine with HPA for automatic scaling\napiVersion: autoscaling/v2beta1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: elastic-app-hpa\nspec:\n  minReplicas: 1\n  maxReplicas: 100\n  metrics:\n    - resource:\n        name: cpu\n        targetAverageUtilization: 2\n      type: Resource\n  scaleTargetRef:\n    apiVersion: apps.kruise.io/v1alpha1\n    kind: UnitedDeployment\n    name: elastic-app\n")),(0,o.kt)("h2",{id:"case-study-2-allocating-different-resources-to-pods-with-different-cpu-types"},"Case Study 2: Allocating Different Resources to Pods with Different CPU Types"),(0,o.kt)("p",null,"In this case, a company purchased several cloud server instances with Intel, AMD, and ARM platform CPUs to prepare for\nlaunching a new service. They wanted Pods scheduled on different platforms to exhibit similar performance.\nAfter stress testing, it was found that, compared to Intel CPUs as the benchmark, AMD platforms needed more\nCPU cores, while ARM platforms required more memory."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps.kruise.io/v1alpha1\nkind: UnitedDeployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    deploymentTemplate:\n      ... # Omitted business workload template\n  topology:\n    # Intel, AMD, and Yitian 710 ARM machines carry 50%, 25%, and 25% of the replicas respectively\n    subsets:\n      - name: intel\n        replicas: 50%\n        nodeSelectorTerm:\n          ... # Select Intel node pool through labels\n        patch:\n          spec:\n            containers:\n              - name: main\n                resources:\n                  limits:\n                    cpu: 2000m\n                    memory: 4000Mi\n      - name: amd64\n        replicas: 25%\n        nodeSelectorTerm:\n          ... # Select AMD node pool through labels\n        # Allocate more CPU to AMD platform\n        patch:\n          spec:\n            containers:\n              - name: main\n                resources:\n                  limits:\n                    cpu: 3000m\n                    memory: 4000Mi\n      - name: yitian-arm\n        replicas: 25%\n        nodeSelectorTerm:\n          ... # Select ARM node pool through labels\n        # Allocate more memory to ARM platform\n        patch:\n          spec:\n            containers:\n              - name: main\n                resources:\n                  limits:\n                    cpu: 2000m\n                    memory: 6000Mi\n")),(0,o.kt)("h1",{id:"summary"},"Summary"),(0,o.kt)("p",null,"Elastic computing power can significantly reduce business costs and effectively increase the performance ceiling of\nservices. To make good use of elastic computing power, it is necessary to choose appropriate elastic components based\non specific application characteristics. The following table summarizes the capabilities of the two components\nintroduced\nin this article, hoping to provide some reference."),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Component"),(0,o.kt)("th",{parentName:"tr",align:null},"Partition Principle"),(0,o.kt)("th",{parentName:"tr",align:null},"Ease of Modification"),(0,o.kt)("th",{parentName:"tr",align:null},"Granularity of Partition"),(0,o.kt)("th",{parentName:"tr",align:null},"Elasticity Capability"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"WorkloadSpread"),(0,o.kt)("td",{parentName:"tr",align:null},"Modify Pods via Webhook"),(0,o.kt)("td",{parentName:"tr",align:null},"High"),(0,o.kt)("td",{parentName:"tr",align:null},"Medium"),(0,o.kt)("td",{parentName:"tr",align:null},"Medium")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"UnitedDeployment"),(0,o.kt)("td",{parentName:"tr",align:null},"Create multiple workloads via templates"),(0,o.kt)("td",{parentName:"tr",align:null},"Low"),(0,o.kt)("td",{parentName:"tr",align:null},"High"),(0,o.kt)("td",{parentName:"tr",align:null},"High")))))}m.isMDXComponent=!0}}]);